\subsection{Creating Rapport Agents using Rule-Based Approaches}
\label{sub:sec:rulebasedAgents}

In the context of the document, we consider rule-based systems as systems that use rules implicitly or explicitly. For example, the former mimics head gestures using motion sensors and the latter generates backchannel behaviours if the conversational partner pauses his speech for more than one second. Rule-based systems are great for deterministic scenarios where the agent does not need to be as robust as other systems used in non-deterministic scenarios~\cite{Mutlu2006} where rules might not be easy to define. However, these systems are not easily ported to other scenarios, nor are they easily scalable because they are often based on non-trivial conditions~\cite{Kok2012}, and are often specifically tailored to discrete scenarios.

Mutlu et al., implemented a scripted mutual gaze agent that synchronises gaze behaviour with pre-recorded voice and gestures~\cite{Mutlu2006}. In their experience, they concluded that participants would recall the story better when the robot looked at them more. Additionally, using the same gaze frequency, women felt better when the storytelling agent gazed less at them. This is important if we want to develop agents for education scenarios where transmitting information is crucial.

Stanton et al., developed a robot assistant for a cooperative visual tracking game (the ``shell game'')~\cite{Stanton2014}. Volunteers would ask the robot for help. However, occasionally, the robot would volunteer to give an answer. In their experiment, they concluded that eye gaze can have powerful effects upon participant decision-making and behaviour, and influence their task performance. For example, humans tend to comply to the robot's suggestion when it gazed at them on harder tasks but, on easier tasks, gaze reduced trust. The authors postulates that ``robot gaze can have either a positive or negative impact upon trust and compliance, depending upon the nature of the robotâ€™s request or suggestion''.

Andrist et al., developed a virtual agent focused on mutual-gaze behaviour in a therapy scenario~\cite{Andrist2015} that would systematically swap its gazing target between the task area and the conversational partner's using tracking sensors. According to their study, matching gaze behaviour models to the user's personality increases motivation and engagement in repetitive tasks. In other words, different personalities require different rules. For example, between tasks, when therapists would provide encouragement, introverts shift more often their gaze to the therapist than extroverts.

%Chidambaram \textit{et al.}, developed a robotic agent to study the impact of vocal and bodily cues in persuasion~\cite{Chidambaram2012} on Desert Survival Tasks~\cite{30} using gaze, gestures, vocal cues and even proximity to the user. In their findings, they concluded that the presence of non-verbal behaviours impacts people's compliance while and that vocal cues do not. However, the study was made on a hypothetical scenario and it was